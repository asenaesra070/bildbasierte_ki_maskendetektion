{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bild Basierte KI\n",
    " \n",
    "                                 bildbasierte_ki_maskendetektion*\n",
    "\n",
    "1. ein System zu bauen, das mÃ¶glichst zuverlÃ¤ssig zwischen maskierten und unmaskierten Gesichtern unterscheiden kann.\n",
    "\n",
    "2.  Zum Einsatz kommt das Ã¶ffentliche Real-World Masked Face Dataset (RMFD), das reale Bilder in zwei Klassen unterteilt: with_mask und without_mask. Der Datensatz eignet sich gut fÃ¼r ein binÃ¤res Klassifikationsproblem im Bereich der bildbasierten KI.\n",
    "\n",
    "3. Vergleich zwischen zwei unterschiedlichen Modellarchitekturen\n",
    "\t1.einfaches CNN mit mehreren Convolution- und Dense-Schichten implementiert\n",
    "\t2. vortrainiertes ResNet-50 Modell verwendet, transfer learning \n",
    "\n",
    "4. Accuracy, Loss, Precision und die Confusion Matrix ausgewertet\n",
    "\n",
    "5. Plot --> Trainings und Validierungs , Loss fÃ¼r jede Epochs\n",
    "\n",
    "\n",
    "\n",
    "                               * Bounding Box fÃ¼r Bildern : OBJEKTDETECTION X\n",
    "\tIoU â€“ Intersection over Union : Was misst es?\n",
    "\tWie stark sich eine vorhergesagte Box mit der tatsÃ¤chlichen Box (Ground Truth) Ã¼berschneidet.\n",
    "\t\t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ğŸ§  Modelle:\n",
    "1. Simpl CNN (Pytorch Dokumentation) mit Conv2D + MaxPool\n",
    "    * Dropout + Dense(128) â†’ Dense(1, sigmoid) - nicht Droupout\n",
    "    * Adam Optimizer, BinaryCrossEntropy\n",
    "2. Transfer Learning â€“ ResNet50\n",
    "    * torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "â€“ Ã„ndere die letzte Ebene und passe sie an deine eigene Klasse an (fc = nn.Linear(512, 1)).\n",
    "â€“ Du kannst das Training einfrieren und anschlieÃŸend optimieren. ??\n",
    "\n",
    "ğŸ“Š Metric & Output:\n",
    "-Accuracy, Precision, Recall, F1-score\n",
    "-Train/Val loss/accuracy grafikleri\n",
    "-Confusion Matrix\n",
    "-5-10 Ã¶rnek gÃ¶rsel + modelin tahmin sonucu (sunumda etkili olur)\n",
    "\n",
    "\n",
    "## Wichtig\n",
    "â€Zum Vergleich wurde auch eine Variante mit 5x5-Filtern getestet.\n",
    "Dabei zeigte sich, dass kleinere Filter (3x3) in diesem Fall zu besseren Ergebnissen fÃ¼hrten, \n",
    "da sie feine Unterschiede im Bereich der Maske besser erfassen konnten.â€œ\n",
    "\n",
    "ğŸ“¦ Alternative: Experimentieren Sie mit kleineren Datenmengen.\n",
    "TEILEN SIE UNS DAVON IM BERICHT E DATENSATZ MIT!\n",
    "\n",
    "torch.save(model.state_dict(), \"results/simple_cnn_model.pth\")\n",
    "\n",
    "## Wichtig\n",
    "\n",
    "ğŸ”œ Vergleich mit ResNet50 Transfer Learning\n",
    "torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "Ersetzen Sie die letzte Ebene durch nn.Linear(..., 2)\n",
    "\n",
    "Wenden Sie den gleichen Trainingszyklus an\n",
    "\n",
    "* Ich mÃ¶chte conf_matrix mit Tools wie matplotlib/seaborn visualisieren. Fragen Sie im Chat\n",
    "\n",
    "ğŸ“Œ conf_matrix = confusion_matrix(all_labels, all_preds) :\n",
    "\n",
    "TÃ¤tsaÃ¤chlich Labels (all_labels)\n",
    "\n",
    "Vergleicht die Vorhersagen des Modells (all_preds)\n",
    "\n",
    "und gibt eine numerische Matrix zurÃ¼ck:\n",
    "\n",
    "Beispiel:\n",
    "[[850 150]\n",
    "[ 95 905]]\n",
    "\n",
    "ğŸ¯ Was bedeutet das?\n",
    "Vorhersage: 0 (unmaskiert) Vorhersage: 1 (maskiert)\n",
    "Wahr: 0 (unmaskiert) 850 (âœ” Richtige Vorhersage: TN) 150 (Falsch: FP)\n",
    "Wahr: 1 (maskiert) 95 (Falsch: FN) 905 (âœ” Richtige Vorhersage: TP)\n",
    "\n",
    "# Beschreibung:\n",
    "\n",
    "    * Genauigkeit: Der Prozentsatz der korrekten Vorhersagen aller Vorhersagen. (TP + TN) / Gesamtmetriken\n",
    "    \n",
    "    * PrÃ¤zision: Wie viele der Beispiele, bei denen wir â€Es gibt eine Maskeâ€œ angegeben haben, waren tatsÃ¤chlich Masken? TP / (TP + FP)\n",
    "    \n",
    "    * RÃ¼ckruf: Wie viele Masken haben wir korrekt vorhergesagt? TP / (TP + FN)\n",
    "    \n",
    "    * F1-Score: Der ausgeglichene Durchschnitt aus PrÃ¤zision und RÃ¼ckruf: 2 * (P * R) / (P + R)\n",
    "    \n",
    "    * Konfusionsmatrix: Die Anzahl der wahren und vorhergesagten Werte in jeder Zelle. Je stÃ¤rker die Diagonale, desto genauer das Modell.\n",
    "\n",
    "\n",
    "Validerung(Test) Datensatz Metrics\n",
    "Mein GerÃ¤t: cpu\n",
    "Wo ist SimpleCNN im GerÃ¤t?  cpu\n",
    "Accuracy: 0.9207\n",
    "Precision: 0.9064\n",
    "Recall: 1                        ----> ETWAS FALSCH CHECK WIEDER MORGEN\n",
    "F1-Score: 0.9221\n",
    "Confusion Matrix:\n",
    " [[1156  124]\n",
    " [  79 1201]]\n"
   ],
   "id": "e5639e2a78a55141"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Functoion Lernen \n",
    "ğŸ¯ 1. Warum wurde CrossEntropyLoss() gewÃ¤hlt?\n",
    "\n",
    "Weil diese Verlustfunktion:\n",
    "ğŸ”¸ Speziell fÃ¼r Klassifizierungsaufgaben entwickelt wurde\n",
    "\n",
    "ğŸ”¸ Die Ausgabe des Modells (Logits) mit den tatsÃ¤chlichen Labels vergleicht\n",
    "\n",
    "ğŸ”¸ LogSoftmax und Negative Log-Likelihood Loss sind bereits kombiniert\n",
    "â†’ Sie mÃ¼ssen also kein zusÃ¤tzliches Softmax anwenden\n",
    "\n",
    "\n",
    "ğŸ§  2. Warum wurde Adam gewÃ¤hlt?\n",
    "\n",
    "Weil Adam:\n",
    "ğŸ”¸ Ein adaptiver MomentenschÃ¤tzungsalgorithmus ist.\n",
    "\n",
    "ğŸ”¸ Er passt sowohl das Momentum (Durchschnitt vergangener Steigungen) als auch die Lernrate an.\n",
    "\n",
    "ğŸ”¸ Er sorgt fÃ¼r einen stabileren und schnelleren Lernprozess.\n",
    "\n",
    "Vorteile:\n",
    "Funktionsbeschreibung\n",
    "Automatische Anpassung der Lernrate an jeden Parameter.\n",
    "Kombination aus Momentum und RMSprop. Passt Richtung und Betrag gut an.\n",
    "Anfangs nicht empfindlich. Kleine DatensÃ¤tze und niedrige Lernrate sind kein Problem.\n",
    "\n",
    "ğŸ” Adam funktioniert also in fast jedem Projekt gut â€“ deshalb ist er so weit verbreitet.\n",
    "In anspruchsvolleren Projekten kÃ¶nnen AdamW, SGD+Momentum, Lookahead usw. ausprobiert werden, aber Adam wird immer noch am hÃ¤ufigsten verwendet.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## MeinungPlatz\n",
    "FÃ¼r die binÃ¤re Klassifikation wurde die Verlustfunktion CrossEntropyLoss verwendet, da sie direkt die Wahrscheinlichkeitsverteilung der Ausgaben mit den echten Klassen vergleicht. \n",
    "Als Optimierer wurde Adam eingesetzt, welcher sich aufgrund seiner stabilen Lernratenanpassung fÃ¼r viele Deep-Learning-Aufgaben als sehr robust erwiesen hat.\n",
    "\n",
    "ERROR : circular import ?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Der Optimierer dient dazu, das Modell weights (die Gewichte) zu verbessern, also lernfÃ¤hig zu machen. \n",
    "Adam Optimizer (Adaptive Moment): ist ein Optimierungsalgorithmus: Es bietet ein stabileres und schnelleres \n",
    "Training durch automatische Anpassung der Lernrate.\"\"\"\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\"\"\"CrossEntropyLoss ist eine Verlustfunktion, die bei Klassifizierungsproblemen verwendet wird.\n",
    "Es misst den Unterschied zwischen den Vorhersagen des Modells (Ausgabe-Logits) und den tatsÃ¤chlichen Labels.\n",
    "Wir erwarten klein loss wert\"\"\"\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ],
   "id": "750a04a4bbf99842"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "test/sample_prediction.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Feature Extraction\n",
    "âœ… Feature Extraction bedeutet:\n",
    "\n",
    "Nur die letzten Schichten (Classifier) werden trainiert\n",
    "\n",
    "Alle anderen Layer bleiben gefroren (gewichten unverÃ¤ndert)\n",
    "\n",
    "Vorteil: schnelleres Training, weniger Overfitting auf kleinem Datensatz\n",
    "\n",
    "Beispielhaft:\n",
    "\n",
    "In deinem Maskendetektion-Projekt bedeutet das, du nutzt die ImageNet-vorgelernten Features, trainierst aber nur den letzten Klassifikator neu auf â€with_maskâ€œ und â€without_maskâ€œ."
   ],
   "id": "adf5e2c91ca1f3f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Was ist Fine Tuning? Wird es hier gemacht?\n",
    "âœ… Definition Fine-Tuning:\n",
    "\n",
    "Alle Gewichte werden weitertrainiert\n",
    "\n",
    "Modell passt sich dem neuen Datensatz komplett an\n",
    "\n",
    "âœ… Feature-Extraction â‰  Fine-Tuning\n",
    "\n",
    "Nur letzter Layer wird trainiert\n",
    "\n",
    "Encoder bleibt fix"
   ],
   "id": "cba5d7adbbf9b516"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
