{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bild Basierte KI\n",
    " \n",
    "                                 bildbasierte_ki_maskendetektion*\n",
    "\n",
    "1. ein System zu bauen, das möglichst zuverlässig zwischen maskierten und unmaskierten Gesichtern unterscheiden kann.\n",
    "\n",
    "2.  Zum Einsatz kommt das öffentliche Real-World Masked Face Dataset (RMFD), das reale Bilder in zwei Klassen unterteilt: with_mask und without_mask. Der Datensatz eignet sich gut für ein binäres Klassifikationsproblem im Bereich der bildbasierten KI.\n",
    "\n",
    "3. Vergleich zwischen zwei unterschiedlichen Modellarchitekturen\n",
    "\t1.einfaches CNN mit mehreren Convolution- und Dense-Schichten implementiert\n",
    "\t2. vortrainiertes ResNet-50 Modell verwendet, transfer learning \n",
    "\n",
    "4. Accuracy, Loss, Precision und die Confusion Matrix ausgewertet\n",
    "\n",
    "5. Plot --> Trainings und Validierungs , Loss für jede Epochs\n",
    "\n",
    "\n",
    "\n",
    "                               * Bounding Box für Bildern : OBJEKTDETECTION X\n",
    "\tIoU – Intersection over Union : Was misst es?\n",
    "\tWie stark sich eine vorhergesagte Box mit der tatsächlichen Box (Ground Truth) überschneidet.\n",
    "\t\t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "🧠 Modelle:\n",
    "1. Simpl CNN (Pytorch Dokumentation) mit Conv2D + MaxPool\n",
    "    * Dropout + Dense(128) → Dense(1, sigmoid) - nicht Droupout\n",
    "    * Adam Optimizer, BinaryCrossEntropy\n",
    "2. Transfer Learning – ResNet50\n",
    "    * torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "– Ändere die letzte Ebene und passe sie an deine eigene Klasse an (fc = nn.Linear(512, 1)).\n",
    "– Du kannst das Training einfrieren und anschließend optimieren. ??\n",
    "\n",
    "📊 Metric & Output:\n",
    "-Accuracy, Precision, Recall, F1-score\n",
    "-Train/Val loss/accuracy grafikleri\n",
    "-Confusion Matrix\n",
    "-5-10 örnek görsel + modelin tahmin sonucu (sunumda etkili olur)\n",
    "\n",
    "\n",
    "## Wichtig\n",
    "„Zum Vergleich wurde auch eine Variante mit 5x5-Filtern getestet.\n",
    "Dabei zeigte sich, dass kleinere Filter (3x3) in diesem Fall zu besseren Ergebnissen führten, \n",
    "da sie feine Unterschiede im Bereich der Maske besser erfassen konnten.“\n",
    "\n",
    "📦 Alternative: Experimentieren Sie mit kleineren Datenmengen.\n",
    "TEILEN SIE UNS DAVON IM BERICHT E DATENSATZ MIT!\n",
    "\n",
    "torch.save(model.state_dict(), \"results/simple_cnn_model.pth\")\n",
    "\n",
    "## Wichtig\n",
    "\n",
    "🔜 Vergleich mit ResNet50 Transfer Learning\n",
    "torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "Ersetzen Sie die letzte Ebene durch nn.Linear(..., 2)\n",
    "\n",
    "Wenden Sie den gleichen Trainingszyklus an\n",
    "\n",
    "* Ich möchte conf_matrix mit Tools wie matplotlib/seaborn visualisieren. Fragen Sie im Chat\n",
    "\n",
    "📌 conf_matrix = confusion_matrix(all_labels, all_preds) :\n",
    "\n",
    "Tätsaächlich Labels (all_labels)\n",
    "\n",
    "Vergleicht die Vorhersagen des Modells (all_preds)\n",
    "\n",
    "und gibt eine numerische Matrix zurück:\n",
    "\n",
    "Beispiel:\n",
    "[[850 150]\n",
    "[ 95 905]]\n",
    "\n",
    "🎯 Was bedeutet das?\n",
    "Vorhersage: 0 (unmaskiert) Vorhersage: 1 (maskiert)\n",
    "Wahr: 0 (unmaskiert) 850 (✔ Richtige Vorhersage: TN) 150 (Falsch: FP)\n",
    "Wahr: 1 (maskiert) 95 (Falsch: FN) 905 (✔ Richtige Vorhersage: TP)\n",
    "\n",
    "# Beschreibung:\n",
    "\n",
    "    * Genauigkeit: Der Prozentsatz der korrekten Vorhersagen aller Vorhersagen. (TP + TN) / Gesamtmetriken\n",
    "    \n",
    "    * Präzision: Wie viele der Beispiele, bei denen wir „Es gibt eine Maske“ angegeben haben, waren tatsächlich Masken? TP / (TP + FP)\n",
    "    \n",
    "    * Rückruf: Wie viele Masken haben wir korrekt vorhergesagt? TP / (TP + FN)\n",
    "    \n",
    "    * F1-Score: Der ausgeglichene Durchschnitt aus Präzision und Rückruf: 2 * (P * R) / (P + R)\n",
    "    \n",
    "    * Konfusionsmatrix: Die Anzahl der wahren und vorhergesagten Werte in jeder Zelle. Je stärker die Diagonale, desto genauer das Modell.\n",
    "\n",
    "\n",
    "Validerung(Test) Datensatz Metrics\n",
    "Mein Gerät: cpu\n",
    "Wo ist SimpleCNN im Gerät?  cpu\n",
    "Accuracy: 0.9207\n",
    "Precision: 0.9064\n",
    "Recall: 1                        ----> ETWAS FALSCH CHECK WIEDER MORGEN\n",
    "F1-Score: 0.9221\n",
    "Confusion Matrix:\n",
    " [[1156  124]\n",
    " [  79 1201]]\n"
   ],
   "id": "e5639e2a78a55141"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Functoion Lernen \n",
    "🎯 1. Warum wurde CrossEntropyLoss() gewählt?\n",
    "\n",
    "Weil diese Verlustfunktion:\n",
    "🔸 Speziell für Klassifizierungsaufgaben entwickelt wurde\n",
    "\n",
    "🔸 Die Ausgabe des Modells (Logits) mit den tatsächlichen Labels vergleicht\n",
    "\n",
    "🔸 LogSoftmax und Negative Log-Likelihood Loss sind bereits kombiniert\n",
    "→ Sie müssen also kein zusätzliches Softmax anwenden\n",
    "\n",
    "\n",
    "🧠 2. Warum wurde Adam gewählt?\n",
    "\n",
    "Weil Adam:\n",
    "🔸 Ein adaptiver Momentenschätzungsalgorithmus ist.\n",
    "\n",
    "🔸 Er passt sowohl das Momentum (Durchschnitt vergangener Steigungen) als auch die Lernrate an.\n",
    "\n",
    "🔸 Er sorgt für einen stabileren und schnelleren Lernprozess.\n",
    "\n",
    "Vorteile:\n",
    "Funktionsbeschreibung\n",
    "Automatische Anpassung der Lernrate an jeden Parameter.\n",
    "Kombination aus Momentum und RMSprop. Passt Richtung und Betrag gut an.\n",
    "Anfangs nicht empfindlich. Kleine Datensätze und niedrige Lernrate sind kein Problem.\n",
    "\n",
    "🔁 Adam funktioniert also in fast jedem Projekt gut – deshalb ist er so weit verbreitet.\n",
    "In anspruchsvolleren Projekten können AdamW, SGD+Momentum, Lookahead usw. ausprobiert werden, aber Adam wird immer noch am häufigsten verwendet.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## MeinungPlatz\n",
    "Für die binäre Klassifikation wurde die Verlustfunktion CrossEntropyLoss verwendet, da sie direkt die Wahrscheinlichkeitsverteilung der Ausgaben mit den echten Klassen vergleicht. \n",
    "Als Optimierer wurde Adam eingesetzt, welcher sich aufgrund seiner stabilen Lernratenanpassung für viele Deep-Learning-Aufgaben als sehr robust erwiesen hat.\n",
    "\n",
    "ERROR : circular import ?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Der Optimierer dient dazu, das Modell weights (die Gewichte) zu verbessern, also lernfähig zu machen. \n",
    "Adam Optimizer (Adaptive Moment): ist ein Optimierungsalgorithmus: Es bietet ein stabileres und schnelleres \n",
    "Training durch automatische Anpassung der Lernrate.\"\"\"\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\"\"\"CrossEntropyLoss ist eine Verlustfunktion, die bei Klassifizierungsproblemen verwendet wird.\n",
    "Es misst den Unterschied zwischen den Vorhersagen des Modells (Ausgabe-Logits) und den tatsächlichen Labels.\n",
    "Wir erwarten klein loss wert\"\"\"\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ],
   "id": "750a04a4bbf99842"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "test/sample_prediction.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Feature Extraction\n",
    "✅ Feature Extraction bedeutet:\n",
    "\n",
    "Nur die letzten Schichten (Classifier) werden trainiert\n",
    "\n",
    "Alle anderen Layer bleiben gefroren (gewichten unverändert)\n",
    "\n",
    "Vorteil: schnelleres Training, weniger Overfitting auf kleinem Datensatz\n",
    "\n",
    "Beispielhaft:\n",
    "\n",
    "In deinem Maskendetektion-Projekt bedeutet das, du nutzt die ImageNet-vorgelernten Features, trainierst aber nur den letzten Klassifikator neu auf „with_mask“ und „without_mask“."
   ],
   "id": "adf5e2c91ca1f3f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Was ist Fine Tuning? Wird es hier gemacht?\n",
    "✅ Definition Fine-Tuning:\n",
    "\n",
    "Alle Gewichte werden weitertrainiert\n",
    "\n",
    "Modell passt sich dem neuen Datensatz komplett an\n",
    "\n",
    "✅ Feature-Extraction ≠ Fine-Tuning\n",
    "\n",
    "Nur letzter Layer wird trainiert\n",
    "\n",
    "Encoder bleibt fix"
   ],
   "id": "cba5d7adbbf9b516"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
